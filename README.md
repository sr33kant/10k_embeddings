# 10k_embeddings

Most of the code for getting data from sec has been forked from sec edgar repository . I made a couple of modifications to download multiple files parallely and BeautifuSoup to clean HTML tags from files. Merged files downloaded  into a single text and pre processed data to remove numbers , punctuations and any non alpha numeric characters. Used Gensim library to create bi-grams . Could extend that corpus to include tri-grams. Used Keras with tensorflow backend to create word vector with demensions 200 , window size 5 and a threshold for words to appear in the corpus is also 5. 
